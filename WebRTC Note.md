## 5月28日

1、[webRTC的标准与发展 (juejin.cn)](https://juejin.cn/post/6967159163633795103)

（1）浏览器将音视频处理和传输的复杂性的大部分从三个主要API中抽象出来：

`MediaStream`：获取音频和视频流

`RTCPeerConnection`：音频和视频数据的通信

`RTCDataChannel`：任意应用程序数据的通信

（2）WebRTC通过UDP传输其数据。但是，UDP只是一个起点。要使浏览器中的实时通信成为现实，它需要花费比原始UDP多得多的费用。

（3）WebRTC体系结构由十几种不同的标准组成，涵盖了应用程序和浏览器API，以及使其工作所需的许多不同的协议和数据格式：

Web实时通信（WEBRTC）W3C工作组负责定义浏览器API。

Web浏览器中的实时通信（RTCWEB）是IETF工作组，负责定义协议，数据格式，安全性和所有其他必要方面，以实现浏览器中的对等通信。

（4）实现低延迟，对等传输是一项不平凡的工程挑战：NAT遍历和连接性检查，信令，安全性，拥塞控制以及无数其他细节需要处理。

2、[硬货专栏 ｜深入浅出 WebRTC AEC（声学回声消除） (qq.com)](https://mp.weixin.qq.com/s/iq6EWCQHoYTtAwZBzs8tYA)

（1）音频方面熟知的 3A 算法（AGC: Automatic gain control; ANS: Adaptive noise suppression; AEC: Acoustic echo cancellation）。

（2）文章结构：回声的形成，回声消除的本质，信号处理流程，线性滤波，非线性滤波，延时调整策略，总结与优化方向。

（3）回声如何形成和回声消除的本质的讲得比较详细，配合图观看。

（4）噪声抑制需要准确估计出噪声信号

平稳噪声可以通过语音检测判别有话端与无话端的状态来动态更新噪声信号，进而参与降噪，常用的手段是基于谱减法(即在原始信号的基础上减去估计出来的噪声所占的成分)的一系列改进方法，其效果依赖于对噪声信号估计的准确性。

对于非平稳噪声，目前用的较多的就是基于递归神经网络的深度学习方法，很多 Windows 设备上都内置了基于多麦克风阵列的降噪的算法。效果上，为了保证音质，噪声抑制允许噪声残留，只要比原始信号信噪比高，噪且听觉上失真无感知即可。

（5）单声道的声源分离

科学家们一直在致力于用技术手段从单声道录音中分离出各种成分，一直以来的难点，随着机器学习技术的应用，使得该技术慢慢变成了可能，但是较高的计算复杂度等原因，距离 RTC 这种低延时系统中的商用还是有一些距离。

（6）回声消除

回声消除就是要将混合后的远端信号过滤掉。

噪声抑制与声源分离都是单源输入，只需要近端采集信号即可，傲娇的回声消除需要同时输入近端信号与远端参考信号。

由于房间的混音效果，参考的远端信号与扬声器播放出来的远端信号已经是“貌合神离”了，与降噪的方法相结合也是不错的思路，但是直接套用降噪的方法显然会造成回声残留与双讲部分严重的抑制。

WebRTC AEC 算法包含了延时调整策略，线性回声估计，非线性回声抑制 3 个部分。

（8）线性滤波

线性回声 y'(n) 可以理解为是远端参考信号 x(n) 经过房间冲击响应之后的结果，线性滤波的本质也就是在估计一组滤波器使得 y'(n) 尽可能的等于 x(n)。

（9）非线性滤波

根据线性部分提供的估计的回声信号，计算信号间的相干性，判别远近端帧状态。

调整抑制系数，计算非线性滤波参数。

（10）滤波部分的细节较复杂，需要时再看。

## 6月1日

1、[新的Google Lyra音频编解码器对实时视频流意味着什么？ (juejin.cn)](https://juejin.cn/post/6968264795787100174)

（1）介绍了一种新的音频编解码格式Lyra，能在3kbps的码率下提供可通信的音频流。

（2）Duo是谷歌开发的一款视频聊天应用，不过好像不太流行。

（3）通过将算法处理限制在300hz到18khz之间的全部或部分声波频率，新旧语音编解码器都比支持人类可听到的全范围声音的音频编解码器具有更高的带宽效率。

（4）视频流中使用最广泛的音频编解码器——高级音频编码(AAC)，通常覆盖0至96 kHz的频率范围，通过使用低频增强(LFE)、用于环绕声和其他高级声学中使用的低音箱馈源，可将频率范围扩展至120khz。

（5）AAC被纳入H.264/AVC标准，在使用48 kHz编码采样率的典型立体声设置时消耗带宽为96 kbps，尽管纯音乐应用程序通常以更高的采样率使用AAC，码率一直延伸到512 kbps。相比之下，在WebRTC流媒体通信（包括Duo的）中使用最广泛的下一代语音编解码器Opus，仅以32 kbps的速度就能近乎完美地复制语音，并以低至6 kbps的码率提供可行的语音通信。

（6）包括 Lyra 和 Opus 在内的许多语音编解码器在带宽受到严重限制下，可以通过将声音复制限制在300hz到8khz甚至500hz到3khz的低频范围内。即使是听起来很糟糕的语音，也足以传达可理解的内容。这些频率范围可以将可理解语音使用的最小码率降低到3 kbps以下水平。

（7）Red5 pro是一款流媒体服务器，支持RTMP, RTSP, HLS, Websocket等协议。

## 6月3日

1、[WebRTC对你意味着什么 (juejin.cn)](https://juejin.cn/post/6969420926509121550)

（1）WebRTC并不是一个完整的视频会议系统，它是一套内置在浏览器中的工具。

（2）WebRTC提供的主要能力：

从电脑的麦克风和摄像头捕捉音频和视频。这也包括所谓的声学回声消除：即使人们不戴耳机，也能消除回声（希望如此）。

允许两个端点协商它们的能力（例如“我想用AV1编解码器发送和接收1080p的视频”），并达成一组共同的参数。

在你和通话中的其他人之间建立安全连接。这包括通过网络上的任何NAT或防火墙获取数据。

将音频和视频压缩后传输给对方，然后在收到后重组。此外还需要处理部分数据丢失的情况，在这种情况下，你要避免出现影响定格或听到音频故障。

（3）WebRTC的安全性

因为WebRTC完全在浏览器中运行，这意味着你不需要担心视频会议提供商想让你下载的软件中的安全问题。

浏览器控制了对摄像头和麦克风的访问。这意味着你可以很容易地阻止站点使用它们，以及确定它们何时使用。

WebRTC在传输过程中一直都是加密的，不需要视频会议系统做其他的事，所以你大多不用问供应商的加密工作做得好不好。

（4）Zoom Web客户端只部分使用了WebRTC。Zoom Web使用WebRTC采集音频和视频并在网络上传输媒体，但在本地使用WebAssembly完成所有音频和视频。

2、[5分钟看懂WebAssembly - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/158042212)

（1）2019 年 12 月 5 日，WebAssembly正式加入 HTML、CSS 和 JavaScript 的 Web 标准大家庭。

（2）WebAssembly（缩写为 wasm）是一种使用非 JavaScript 代码，并使其在浏览器中运行的方法。这些代码可以是 C、C++ 或 Rust 等。它们会被编译进你的浏览器，在你的 CPU 上以接近原生的速度运行。这些代码的形式是二进制文件，你可以直接在 JavaScript 中将它们当作模块来用。

（3）通过 JavaScript API，你可以将 WebAssembly模块加载到你的页面中。也就是说，你可以通过 WebAssembly来充分利用编译代码的性能，同时保持 JavaScript 的灵活性。

（4）WebAssembly不是编程语言，它是一种中间格式，叫字节码，可以作为其他语言的编译目标。

（5）WebAssembly的工作方式：

第一步：使用 C、C++ 或其他语言生成源代码，这段代码应该可以解决某个问题，或者完成某段对浏览器中的 JavaScript 来说太过复杂的流程。

第二步：使用 Emscripten 将你的源代码编译为 WebAssembly，这一步完成时，你将得到一个 wasm文件。

第三步：你将在网页上使用这个 wasm文件，将来你可以像其他 ES6 模块一样加载这个文件。

3、[详解 WebRTC 高音质低延时的背后 — AGC（自动增益控制） (juejin.cn)](https://juejin.cn/post/6966790083131211807)

（1）自动增益控制（AGC：Auto Gain Control）是我认为链路最长，最影响音质和主观听感的音频算法模块，一方面是 AGC 必须作用于发送端来应对移动端与 PC 端多样的采集设备，另一方面 AGC 也常被作为压限器作用于接收端，均衡混音信号防止爆音。

（2）压限器(Compressor/Limiter)是压缩与限制器的简称。 压缩器：是一种随着输入信号电平增大而本身增益减少的放大器。 限制器：是一种这样的放大器，输出电平到达一定值以后，不管输入电平怎样增加，其最大输出电平保持恒定的放大器。该最大输出电平是可以根据需要调节的。 一般地来讲，压缩器与限制器多是结合在一起出现，有压缩功能的地方同时也就会有限制功能。（百度百科）

（3）优秀的自动增益控制算法能够统一音频音量大小，极大地缓解了由设备采集差异、说话人音量大小、距离远近等因素导致的音量的差异。

（4）AGC 在发送端作为均衡器和压限器调整推流音量，在接收端仅作为压限器防止混音之后播放的音频数据爆音，理论上推流端 AGC 做的足够鲁棒之后，拉流端仅作为压限器是足够的，有的厂家为了进一步减小混音之后不同人声的音量差异也会再做一次 AGC。

## 6月4日

1、[可编程的流式计算框架：YoMo (juejin.cn)](https://juejin.cn/post/6969442775431397412)

（1）5年以后，企业之间比拼的可能就是QUIC协议这种具有开放性的、基于User Space（用户自定义空间）的可以作一些灵活拥塞控制的算法。未来的软硬件可能都是可编程的、开放性的。

（2）低时延：QUIC协议；5G；WIFI6；边缘计算。

（3）WebAssembly现在的趋势是跑在服务器端，相比docker，冷启动比docker快100倍，执行时间也快10%~50%。WebAssembly综合了轻量级、更优的性能、更高的安全性和多语言的特点。

（4）QUIC：基于UDP的改进的传输层协议。优点一个是User space，我在开头开放性那里也提到过User space，可以更方便的进行软件升级。TCP内核态的升级就没有那么方便。二是拥塞控制算法。根据不同的场景进行灵活的控制，具有更高的可编程性。

（5）整个行业的趋势是从之前的大型机通过终端连接变成PC端去中心化场景。发展到移动互联时代又回到了中心化的云计算中心。到IoT时代因为数据量的巨大，需要边缘端进行分布式来缓解云计算中心的压力。边缘计算虽然越来越重要，但是边缘计算并不会取代云计算，他们会共同存在。

（6）边缘计算的优势一是降低传输距离。二是就近计算更快的响应。第三，比较重要，边缘计算可以保护安全隐私。最后一点就是低成本。边缘计算可以减少带宽传递的成本。

（7）云计算的性能更强但时延、带宽成本较高，边缘计算恰恰相反。云计算和边缘计算在使用上互补，以满足不同场景的使用需求。

2、[红遍视频技术圈的webRTC，到底是什么？ (polyv.net)](https://www.polyv.net/news/2019/11/hy0474/)

（1）2个处于不同网络环境的浏览器，要实现语音/视频通讯，难点在哪？

彼此了解对方支持的媒体格式、最大分辨率等信息。

彼此要了解对方的网络情况，才可以找到一条通讯的链路。

难点在于信令服务器。

（2）WebRTC面临的挑战：

传输质量难以保证。webRTC使用的是点对点（P2P）传输，虽然可以节省中间服务器资源，但是很难保证跨国及跨运营商之间通信的质量。

实现多人场景应用需二次开发。

在移动端表现不佳。这点在安卓上比较明显，如果不针对不同机型做适配，很难有统一的用户体验。

（3）WebRTC的未来怎么走？

设备兼容性更强。

QUIC技术逐渐起步。对于webRTC来说，QUIC可以让通信速度更快，减少卡顿，还可以替代之前的旧协议。但目前支持QUIC的浏览器只有 Chrome 和 Opera，推广普及仍需要时间。

应用场景更多元：音视频通信已经不仅限于社交软件的应用。webRTC普及使得教育直播、在线医疗、企业培训等垂直场景应用蓬勃发展。

3、[为何一直推荐WebRTC？ - anyRTC云平台的回答 - 知乎](https://www.zhihu.com/question/50277029/answer/120202418)

大致介绍了WebRTC的音频、视频相关的目录结构：

（1）视频采集---video_capture，源代码在webrtc\modules\video_capture\main目录下；

在windows平台上，WebRTC采用的是dshow技术，来实现枚举视频的设备信息和视频数据的采集，这意味着可以支持大多数的视频采集设备；对那些需要单独驱动程序的视频采集卡（比如海康高清卡）就无能为力了。

（2）视频编解码---video_coding，源代码在webrtc\modules\video_coding目录下；

WebRTC采用I420/VP8编解码技术。VP8是google收购ON2后的开源实现，并且也用在WebM项目中。VP8能以更少的数据提供更高质量的视频，特别适合视频会议这样的需求。

（3）视频加密--video_engine_encryption

视频加密是WebRTC的video_engine一部分，相当于视频应用层面的功能，给点对点的视频双方提供了数据上的安全保证，可以防止在Web上视频数据的泄漏。

（4）视频媒体文件--media_file，源代码在webrtc\modules\media_file目录下；

该功能是可以用本地文件作为视频源，有点类似虚拟摄像头的功能；另外，WebRTC还可以录制音视频到本地文件，比较实用的功能。

（5）视频图像处理--video_processing，源代码在webrtc\modules\video_processing目录下；

视频图像处理针对每一帧的图像进行处理，包括明暗度检测、颜色增强、降噪处理等功能，用来提升视频质量。

（6）视频显示--video_render，源代码在webrtc\modules\video_render目录下；

在windows平台，WebRTC采用direct3d9和directdraw的方式来显示视频，只能这样，必须这样。

（7）音频设备---audio_device，源代码在webrtc\modules\audio_device\main目录下；

（8）音频编解码---audio_coding，源代码在webrtc\modules\audio_coding目录下；

WebRTC采用iLIBC/iSAC/G722/PCM16/RED/AVT编解码技术。WebRTC还提供NetEQ功能---抖动缓冲器及丢包补偿模块，能够提高音质，并把延迟减至最小。另外一个核心功能是基于语音会议的混音处理。

（9）声音加密--voice_engine_encryption

和视频一样，WebRTC也提供声音加密功能。

（10）声音处理--audio_processing，源代码在webrtc\modules\audio_processing目录下；

声音处理针对音频数据进行处理，包括回声消除(AEC)、AECM(AEC Mobile)、自动增益(AGC)、降噪(NS)、静音检测(VAD)处理等功能，用来提升声音质量。

（11）网络传输与流控：WebRTC采用的是成熟的RTP/RTCP技术。

4、[为何一直推荐WebRTC？ - 阿里巴巴淘系技术的回答 - 知乎](https://www.zhihu.com/question/50277029/answer/1628170598)

（1）在直播大趋势下，现在的 WebRTC 开源软件还不能很好地支持直播。但可以基于 WebRTC 进行一些方案改造，实现一秒内的低延迟直播。

（2）低延时直播选型：QUIC和RTC

传输方式：Quic 是可靠传输；而 RTC 是半可靠传输，特定情境下可对音视频有损传输，可有效降低延迟。

复杂度：Quic 的复杂度非常低，相当于将 TCP 接口换位 Quic 接口即可，RTC方案的复杂很高，涉及一整套的协议设计和QOS保障机制。

音视频友好性：Quic 不关心传输内容，对音视频数据透明传输。RTC 对音视频更友好，可针对音视频做定制化优化。

方案完备性：从方案完备性方面来讲，Quic 是针对传输层优化，而 WebRTC 可提供端对端优化方案。

理论延迟：经我们实验室测试以及线上数据分析，WebRTC 方案的延迟可以达到 1 秒以内。QUIC延迟在3秒左右。

（3）终端接入方案：基于WebRTC全模块的接入方案、基于WebRTC传输层的接入方案

基于WebRTC全模块的接入方案：对现有推流端和播放端侵入性极大；WebRTC应用场景是通话，延迟优于画质，RTC技术栈和直播技术栈存在差异；包较大；

基于WebRTC传输层的接入方案：WebRTC只使用核心传输相关模块（RTP/RTCP, FEC, NACK, Jitter buffer, 音视频同步，拥塞控制等），将这些模块封装为ffmpeg插件，注入到ffmpeg中；

## 6月7日

1、[小议WebRTC拥塞控制算法：GCC介绍 (juejin.cn)](https://juejin.cn/post/6844903679602982925)

（1）WebRTC的传输层是基于UDP协议，在此之上，使用的是标准的RTP/RTCP协议封装媒体流。RTP/RTCP本身提供很多机制来保证传输的可靠性，比如RR/SR, NACK，PLI，FIR, FEC，REMB等，同时WebRTC还扩展了RTP/RTCP协议，来提供一些额外的保障，比如Transport-CCFeedback, RTP Transport-wide-cc extension，RTP abs-sendtime extension等。

（2）WebRTC的拥塞控制算法称为GCC，GCC算法主要分成两个部分，一个是基于丢包的拥塞控制，一个是基于延迟的拥塞控制。

在早期的实现当中，这两个拥塞控制算法分别是在发送端和接收端实现的，接收端的拥塞控制算法所计算出的估计带宽，会通过RTCP的remb反馈到发送端，发送端综合两个控制算法的结果得到一个最终的发送码率，并以此码率发送数据包。

（3）基于丢包的拥塞控制

只需要根据从接收端反馈的丢包率，就可以做带宽估算；

基于丢包的拥塞控制比较简单，其基本思想是根据丢包的多少来判断网络的拥塞程度，丢包越多则认为网络越拥塞，那么我们就要降低发送速率来缓解网络拥塞；如果没有丢包，这说明网络状况很好，这时候就可以提高发送码率，向上探测是否有更多的带宽可用。

WebRTC通过RTCP协议的Receive Report反馈包来获取接收端的丢包率。Receive Report包中有一个lost fraction字段，包含了接收端的丢包率。

当丢包率大于10%时则认为网络有拥塞，此时根据丢包率降低带宽，丢包率越高带宽降的越多；当丢包率小于2%时，则认为网络状况很好，此时向上提高5%的带宽以探测是否有更多带宽可用；2%到10%之间的丢包率，则会保持当前码率不变，这样可以避免一些网络固有的丢包被错判为网络拥塞而导致降低码率，而这部分的丢包则需要通过其他的如NACK或FEC等手段来恢复。

（4）基于延迟的拥塞控制

WebRTC使用延迟梯度来判断网络的拥塞程度，为此WebRTC扩展了RTCP协议，其中最主要的是增加了Transport-CC Feedback，该包携带了接收端接收到的每个媒体包的到达时间。

WebRTC扩展了RTP/RTCP协议，其一是增加了RTP扩展头部，添加了一个session级别的sequence number, 目的是基于一个session做反馈信息的统计，而不紧紧是一条音频流或视频流；其二是增加了一个RTCP反馈信息transport-cc-feedback，该消息负责反馈接受端收到的所有媒体包的到达时间。接收端根据包间的接受延迟和发送间隔可以计算出延迟梯度，从而估计带宽。

（5）到达时间滤波器

延迟梯度可以作为判断网络拥塞的依据。用两个数据包的到达时间间隔减去他们的发送时间间隔，就可以得到一个延迟的变化，这里我们称这个延迟的变化为单向延迟梯度。

到达时间滤波器计算每一组数据包的延迟梯度。

（6）过载检测器

过载检测器的主要工作有两部分，一部分是确定阈值的大小，另一部分就是依据延迟梯度和阈值的判断，估计出当前的网络状态，一共有三种网络状态: overuse underuse normal。

阈值是根据延迟梯度自适应动态变化的。

（7）速率控制器

速率控制器主要实现了一个状态机的变迁，并根据当前状态来计算当前的可用码率。

速率控制器根据过载探测器输出的信号（overuse underuse normal）驱动速率控制状态机， 从而估算出当前的网络速率。

最后，将基于丢包的码率估计值和基于延迟的码率估计值作比较，其中最小的码率估价值将作为最终的发送码率。

2、[WebRTC：数据传输相关协议简介 (juejin.cn)](https://juejin.cn/post/6908953140758839303)

（1）加密通道建立

对WebRTC应用来说，不管是音视频数据，还是自定义应用数据，都要求基于加密的信道进行传输。DTLS 有点类似 TLS，在UDP的基础上，实现信道的加密。

DTLS的主要用途，就是让通信双方协商密钥，用来对数据进行加解密。

（2）音视频数据传输

RTP（Realtime Transport Protocol）：实时传输协议，主要用来传输对实时性要求比较高的数据，比如音视频数据。

RTCP（RTP Trasport Control Protocol）：RTP传输控制协议，跟RTP在同一份RFC中定义，主要用来监控数据传输的质量，并给予数据发送方反馈。

SRTP、SRTCP，分别在RTP、RTCP的基础上加了个S(Secure)，表示安全的意思，这个就是DTLS做的事情了。

（3）自定义应用数据传输

SCTP（Stream Control Transmission Protocol）：流控制传输协议。

RTP/RTCP主要用来传输音视频，是为了流媒体设计的。而对于自定义应用数据的传输，WebRTC中使用了SCTP协议。

SCTP依赖DTLS建立的加密信道。

## 阅读计划

[百度App网络深度优化系列《三》弱网优化 (juejin.cn)](https://juejin.cn/post/6844904033723875342#heading-27)

[怎么让不可靠的UDP可靠？-InfoQ](https://www.infoq.cn/article/how-to-make-udp-reliable/)

[WebRTC通话质量调优：三个弱网模拟测试工具的使用与对比 (juejin.cn)](https://juejin.cn/post/6844903715237789709)

[聊聊WebRTC网关服务器1：如何选择服务端端口方案？ - 云信博客 (163.com)](https://yunxin.163.com/blog/webrtc-1/?from=juejin&utm_source=juejin&utm_medium=article&utm_campaign=seo&utm_content=video-tech-19)

[谈谈网络通信中的 ACK、NACK 和 REX - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/104322256)

[QUIC 将会是 WebRTC 的未来么？ (juejin.cn)](https://juejin.cn/post/6844903731754958862)

[WebRTC 学习资源，以及相关 Demo - WebRTC 讨论区 / 资源分享 - RTC开发者社区-WebRTC中文论坛|RTC实时技术论坛 (rtcdeveloper.com)](https://rtcdeveloper.com/t/topic/435)