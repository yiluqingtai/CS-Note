## 5月28日

1、[webRTC的标准与发展 (juejin.cn)](https://juejin.cn/post/6967159163633795103)

（1）浏览器将音视频处理和传输的复杂性的大部分从三个主要API中抽象出来：

`MediaStream`：获取音频和视频流

`RTCPeerConnection`：音频和视频数据的通信

`RTCDataChannel`：任意应用程序数据的通信

（2）WebRTC通过UDP传输其数据。但是，UDP只是一个起点。要使浏览器中的实时通信成为现实，它需要花费比原始UDP多得多的费用。

（3）WebRTC体系结构由十几种不同的标准组成，涵盖了应用程序和浏览器API，以及使其工作所需的许多不同的协议和数据格式：

Web实时通信（WEBRTC）W3C工作组负责定义浏览器API。

Web浏览器中的实时通信（RTCWEB）是IETF工作组，负责定义协议，数据格式，安全性和所有其他必要方面，以实现浏览器中的对等通信。

（4）实现低延迟，对等传输是一项不平凡的工程挑战：NAT遍历和连接性检查，信令，安全性，拥塞控制以及无数其他细节需要处理。

2、[硬货专栏 ｜深入浅出 WebRTC AEC（声学回声消除） (qq.com)](https://mp.weixin.qq.com/s/iq6EWCQHoYTtAwZBzs8tYA)

（1）音频方面熟知的 3A 算法（AGC: Automatic gain control; ANS: Adaptive noise suppression; AEC: Acoustic echo cancellation）。

（2）文章结构：回声的形成，回声消除的本质，信号处理流程，线性滤波，非线性滤波，延时调整策略，总结与优化方向。

（3）回声如何形成和回声消除的本质的讲得比较详细，配合图观看。

（4）后面滤波部分较复杂，还没来得及仔细看。

## 6月1日

1、[新的Google Lyra音频编解码器对实时视频流意味着什么？ (juejin.cn)](https://juejin.cn/post/6968264795787100174)

（1）介绍了一种新的音频编解码格式Lyra，能在3kbps的码率下提供可通信的音频流。

（2）Duo是谷歌开发的一款视频聊天应用，不过好像不太流行。

（3）通过将算法处理限制在300hz到18khz之间的全部或部分声波频率，新旧语音编解码器都比支持人类可听到的全范围声音的音频编解码器具有更高的带宽效率。

（4）视频流中使用最广泛的音频编解码器——高级音频编码(AAC)，通常覆盖0至96 kHz的频率范围，通过使用低频增强(LFE)、用于环绕声和其他高级声学中使用的低音箱馈源，可将频率范围扩展至120khz。

（5）AAC被纳入H.264/AVC标准，在使用48 kHz编码采样率的典型立体声设置时消耗带宽为96 kbps，尽管纯音乐应用程序通常以更高的采样率使用AAC，码率一直延伸到512 kbps。相比之下，在WebRTC流媒体通信（包括Duo的）中使用最广泛的下一代语音编解码器Opus，仅以32 kbps的速度就能近乎完美地复制语音，并以低至6 kbps的码率提供可行的语音通信。

（6）包括 Lyra 和 Opus 在内的许多语音编解码器在带宽受到严重限制下，可以通过将声音复制限制在300hz到8khz甚至500hz到3khz的低频范围内。即使是听起来很糟糕的语音，也足以传达可理解的内容。这些频率范围可以将可理解语音使用的最小码率降低到3 kbps以下水平。

（7）Red5 pro是一款流媒体服务器，支持RTMP, RTSP, HLS, Websocket等协议。

## 6月3日

1、[WebRTC对你意味着什么 (juejin.cn)](https://juejin.cn/post/6969420926509121550)

（1）WebRTC并不是一个完整的视频会议系统，它是一套内置在浏览器中的工具。

（2）WebRTC提供的主要能力：

从电脑的麦克风和摄像头捕捉音频和视频。这也包括所谓的声学回声消除：即使人们不戴耳机，也能消除回声（希望如此）。

允许两个端点协商它们的能力（例如“我想用AV1编解码器发送和接收1080p的视频”），并达成一组共同的参数。

在你和通话中的其他人之间建立安全连接。这包括通过网络上的任何NAT或防火墙获取数据。

将音频和视频压缩后传输给对方，然后在收到后重组。此外还需要处理部分数据丢失的情况，在这种情况下，你要避免出现影响定格或听到音频故障。

（3）WebRTC的安全性

因为WebRTC完全在浏览器中运行，这意味着你不需要担心视频会议提供商想让你下载的软件中的安全问题。

浏览器控制了对摄像头和麦克风的访问。这意味着你可以很容易地阻止站点使用它们，以及确定它们何时使用。

WebRTC在传输过程中一直都是加密的，不需要视频会议系统做其他的事，所以你大多不用问供应商的加密工作做得好不好。

（4）Zoom Web客户端只部分使用了WebRTC。Zoom Web使用WebRTC采集音频和视频并在网络上传输媒体，但在本地使用WebAssembly完成所有音频和视频。

2、[5分钟看懂WebAssembly - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/158042212)

（1）2019 年 12 月 5 日，WebAssembly正式加入 HTML、CSS 和 JavaScript 的 Web 标准大家庭。

（2）WebAssembly（缩写为 wasm）是一种使用非 JavaScript 代码，并使其在浏览器中运行的方法。这些代码可以是 C、C++ 或 Rust 等。它们会被编译进你的浏览器，在你的 CPU 上以接近原生的速度运行。这些代码的形式是二进制文件，你可以直接在 JavaScript 中将它们当作模块来用。

（3）通过 JavaScript API，你可以将 WebAssembly模块加载到你的页面中。也就是说，你可以通过 WebAssembly来充分利用编译代码的性能，同时保持 JavaScript 的灵活性。

（4）WebAssembly不是编程语言，它是一种中间格式，叫字节码，可以作为其他语言的编译目标。

（5）WebAssembly的工作方式：

第一步：使用 C、C++ 或其他语言生成源代码，这段代码应该可以解决某个问题，或者完成某段对浏览器中的 JavaScript 来说太过复杂的流程。

第二步：使用 Emscripten 将你的源代码编译为 WebAssembly，这一步完成时，你将得到一个 wasm文件。

第三步：你将在网页上使用这个 wasm文件，将来你可以像其他 ES6 模块一样加载这个文件。

3、[详解 WebRTC 高音质低延时的背后 — AGC（自动增益控制） (juejin.cn)](https://juejin.cn/post/6966790083131211807)

（1）自动增益控制（AGC：Auto Gain Control）是我认为链路最长，最影响音质和主观听感的音频算法模块，一方面是 AGC 必须作用于发送端来应对移动端与 PC 端多样的采集设备，另一方面 AGC 也常被作为压限器作用于接收端，均衡混音信号防止爆音。

（2）压限器(Compressor/Limiter)是压缩与限制器的简称。 压缩器：是一种随着输入信号电平增大而本身增益减少的放大器。 限制器：是一种这样的放大器，输出电平到达一定值以后，不管输入电平怎样增加，其最大输出电平保持恒定的放大器。该最大输出电平是可以根据需要调节的。 一般地来讲，压缩器与限制器多是结合在一起出现，有压缩功能的地方同时也就会有限制功能。（百度百科）

（3）优秀的自动增益控制算法能够统一音频音量大小，极大地缓解了由设备采集差异、说话人音量大小、距离远近等因素导致的音量的差异。

（4）AGC 在发送端作为均衡器和压限器调整推流音量，在接收端仅作为压限器防止混音之后播放的音频数据爆音，理论上推流端 AGC 做的足够鲁棒之后，拉流端仅作为压限器是足够的，有的厂家为了进一步减小混音之后不同人声的音量差异也会再做一次 AGC。
