## [这可能是你见过的最全的网络爬虫干货总结！ (juejin.cn)](https://juejin.cn/post/6844903697047257101)

1、总结

（1）对于爬取来说，我们需要学会使用不同的方法来应对不同情景下的数据抓取任务。

（2）爬取分为爬取网页和爬取app，爬取网页又分为服务器渲染和客户端渲染，爬取app分为普通接口、加密参数接口、加密内容接口、非常规协议接口。

（3）服务端渲染的意思就是页面的结果是由服务器渲染后返回的，有效信息包含在请求的 HTML 页面里面，比如猫眼电影这个站点。

服务端渲染的情况就比较简单了，用一些基本的 HTTP 请求库就可以实现爬取。

（4）客户端渲染的意思就是页面的主要内容由 JavaScript 渲染而成，真实的数据是通过 Ajax 接口等形式获取的，比如淘宝、微博手机版等等站点。

寻找 Ajax 接口，此种情形可以直接使用 Chrome/Firefox 的开发者工具直接查看 Ajax 具体的请求方式、参数等内容，然后用 HTTP 请求库模拟即可。

模拟浏览器执行，此种情形适用于网页接口和逻辑较为复杂的情况，可以直接以可见即可爬的方式进行爬取，如puppteer。

直接提取 JavaScript 数据，此种情形适用于真实数据没有经过 Ajax 接口获取，而是直接包含在 HTML 结果的某个变量中，直接使用正则表达式将其提取即可。

模拟执行 JavaScript，某些情况下直接模拟浏览器执行效率会偏低，如果我们把 JavaScript 的某些执行和加密逻辑摸清楚了，可以直接执行相关的 JavaScript 来完成逻辑处理和接口请求

2、解析

（1）对于 HTML 类型的页面来说，常用的解析方法其实无非那么几种，正则、XPath、CSS Selector，另外对于某些接口，常见的可能就是 JSON、XML 类型，使用对应的库进行处理即可。

（2）智能解析意思就是说，如果能提供一个页面，算法可以自动来提取页面的标题、正文、日期等内容，同时把无用的信息给刨除。

如果能够容忍一定的错误率，可以使用智能解析来大大节省时间。

3、存储

（1）存储，即选用合适的存储媒介来存储爬取到的结果，包括文件、数据库、搜索引擎、云存储。

4、反爬

（1）爬虫现在已经越来越难了，非常多的网站已经添加了各种反爬措施，在这里可以分为非浏览器检测、封 IP、验证码、封账号、字体反爬等。

5、加速

（1）当爬取的数据量非常大时，如何高效快速地进行数据抓取是关键。常见的措施有多线程、多进程、异步、分布式、细节优化等。

## [爬虫，其实本就是这么简单 (juejin.cn)](https://juejin.cn/post/6844903918816903182)

1、爬虫及Robots协议

（1）爬虫，是一种自动获取网页内容的程序。是搜索引擎的重要组成部分，因此搜索引擎优化很大程度上就是针对爬虫而做出的优化。

爬虫拿到的一段是html代码，所以说这个对于我们来说并不陌生了，只要我们把它转换成DOM树就可以了

（2）Robots协议：robots.txt是一个文本文件，robots.txt是一个协议不是一个命令。robots.txt是爬虫要查看的第一个文件，robots.txt告诉爬虫在服务器上什么文件是可以被查看的，爬虫机器人就会按照文件中的内容来确定访问范围。

（3）爬虫和Robots协议是紧密相连的，网址/robots.txt显示的不允许爬的页面就不要去爬，万一涉及到一些用户隐私等方面的东西，之后会被发现而走到法律途径的。



